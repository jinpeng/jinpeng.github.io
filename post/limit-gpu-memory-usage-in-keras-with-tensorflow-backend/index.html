<!doctype html>
<html lang="en-us">
  <head>
    <title>Limit GPU memory usage in Keras with Tensorflow Backend // Jinpeng&#39;s Blog</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.55.6" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Dong Jinpeng" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://jinpeng.github.com/css/main.min.59023e5fd38d6ecb0e1dfbb295077c3c67e00e3b9eb3feaf34b5a5e6b332897a.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Limit GPU memory usage in Keras with Tensorflow Backend"/>
<meta name="twitter:description" content="问题： 我使用Keras 2.1.6和Tensorflow 1.8.0做一个OCR实验，这个OCR分为两步，第一步Text Localization没有使用Keras，直接使用Tensorflow实现的网络，单独运行正常；第二步Text Recognition使用Keras实现的另一个网络，执行时出现了Out of Memory的警告：
2018-05-18 17:01:53.022692: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11264 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1) 2018-05-18 17:01:53.028636: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_driver.cc:936] failed to allocate 11.00G (11811160064 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY 2018-05-18 17:01:53.031124: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_driver.cc:936] failed to allocate 9.90G (10630043648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY  最后Python进程挂起，并且出现以下错误，创建cudnn handle失败：
2018-05-18 16:47:14.594352: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_dnn."/>

    <meta property="og:title" content="Limit GPU memory usage in Keras with Tensorflow Backend" />
<meta property="og:description" content="问题： 我使用Keras 2.1.6和Tensorflow 1.8.0做一个OCR实验，这个OCR分为两步，第一步Text Localization没有使用Keras，直接使用Tensorflow实现的网络，单独运行正常；第二步Text Recognition使用Keras实现的另一个网络，执行时出现了Out of Memory的警告：
2018-05-18 17:01:53.022692: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11264 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1) 2018-05-18 17:01:53.028636: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_driver.cc:936] failed to allocate 11.00G (11811160064 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY 2018-05-18 17:01:53.031124: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_driver.cc:936] failed to allocate 9.90G (10630043648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY  最后Python进程挂起，并且出现以下错误，创建cudnn handle失败：
2018-05-18 16:47:14.594352: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_dnn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jinpeng.github.com/post/limit-gpu-memory-usage-in-keras-with-tensorflow-backend/" />
<meta property="article:published_time" content="2018-05-18T17:26:19&#43;00:00"/>
<meta property="article:modified_time" content="2018-05-18T17:26:19&#43;00:00"/>


  </head>
  <body>
    <header class="app-header">
      <a href="https://jinpeng.github.com/"><img class="app-header-avatar" src="http://pu9o1rel6.bkt.clouddn.com/cartoon_avatar.jpg" alt="Dong Jinpeng" /></a>
      <h1>Jinpeng&#39;s Blog</h1>
      <p>An old programmer keeps learning new techniques.</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/jinpeng"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
      </div>
      
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Limit GPU memory usage in Keras with Tensorflow Backend</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          May 18, 2018
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          1 min read
        </div></div>
    </header>
    <div class="post-content">
      

<h2 id="问题">问题：</h2>

<p>我使用Keras 2.1.6和Tensorflow 1.8.0做一个OCR实验，这个OCR分为两步，第一步Text Localization没有使用Keras，直接使用Tensorflow实现的网络，单独运行正常；第二步Text Recognition使用Keras实现的另一个网络，执行时出现了Out of Memory的警告：</p>

<pre><code>2018-05-18 17:01:53.022692: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11264 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-05-18 17:01:53.028636: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_driver.cc:936] failed to allocate 11.00G (11811160064 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2018-05-18 17:01:53.031124: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_driver.cc:936] failed to allocate 9.90G (10630043648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
</code></pre>

<p>最后Python进程挂起，并且出现以下错误，创建cudnn handle失败：</p>

<pre><code>2018-05-18 16:47:14.594352: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_dnn.cc:455] could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2018-05-18 16:47:14.596108: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_dnn.cc:427] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2018-05-18 16:47:14.597622: F T:\src\github\tensorflow\tensorflow\core\kernels\conv_ops.cc:713] Check failed: stream-&gt;parent()-&gt;GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo&lt;T&gt;(), &amp;algorithms)
</code></pre>

<p>我使用的主机有一块GTX 1080Ti 11G的显卡，而从错误信息里看，Keras/Tensorflow试图分配全部11G GPU内存，但由于桌面显示也使用同一块显卡，只剩下9.10G显存，因此进程挂起。显然不是根据task所需来分配GPU内存的。查阅资料，发现Keras缺省是要分配全部GPU内存。</p>

<h2 id="解决方法">解决方法：</h2>

<p>Keras本身没有设置GPU内存限制的入口，但Tensorflow的session可以设置，设置以后可以再把session设置给Keras。</p>

<pre><code># limit GPU memory usage, otherwise it will try to allocate all memory and failed with out of memory.
import tensorflow as tf
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.7
from keras.backend.tensorflow_backend import set_session
set_session(tf.Session(config=config))
</code></pre>

<p>上面代码设置每个GPU内存使用上限是70%。</p>

<p>这段代码需要在每次train和inference之前执行，并且在Keras 2.0.9及以上版本，必须要在程序的最开始执行，一旦有Keras的import，它就会query可用的GPU，而在query的过程中会试图分配所有的GPU内存。</p>

<p>看Keras的github issues讨论，Keras团队认为这是Tensorflow的bug，有人认为是Keras 2.0.9引入的bug。没有下文。</p>

<p>测试环境：Windows 10 64bit，Anaconda3 5.1.0，Python 3.6.5，Tensorflow 1.8.0，Keras 2.1.6。</p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
